{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944b3153-5d41-4b8b-a7c0-2f9b5f72e449",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "box2D is not installed, run `pip install gym[box2d]`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gym\\envs\\box2d\\bipedal_walker.py:14\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         circleShape,\n\u001b[0;32m     17\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m         revoluteJointDef,\n\u001b[0;32m     22\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# === TRAINING SCRIPT ===\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunarLander-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     91\u001b[0m     agent \u001b[38;5;241m=\u001b[39m PolicyGradientAgent(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m)\n\u001b[0;32m     92\u001b[0m     n_episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gym\\envs\\registration.py:581\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m spec_\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m load(spec_\u001b[38;5;241m.\u001b[39mentry_point)\n\u001b[0;32m    583\u001b[0m mode \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    584\u001b[0m apply_human_rendering \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gym\\envs\\registration.py:61\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name and returns an environment creation function\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Calls the environment constructor\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(mod_name)\n\u001b[0;32m     62\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:999\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gym\\envs\\box2d\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbipedal_walker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcar_racing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CarRacing\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunar_lander\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gym\\envs\\box2d\\bipedal_walker.py:24\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         circleShape,\n\u001b[0;32m     17\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m         revoluteJointDef,\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox2D is not installed, run `pip install gym[box2d]`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: box2D is not installed, run `pip install gym[box2d]`"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "class PolicyGradientAgent:\n",
    "    def __init__(self, lr, gamma, n_actions=4, l1_size=64, l2_size=64, input_dims=8, chkpt_dir='tmp'):\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.input_dims = input_dims\n",
    "        self.chkpt_file = os.path.join(chkpt_dir, 'policy.ckpt')\n",
    "\n",
    "        self.state_memory = []\n",
    "        self.action_memory = []\n",
    "        self.reward_memory = []\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.build_net()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def build_net(self):\n",
    "        self.input = tf.placeholder(tf.float32, [None, self.input_dims])\n",
    "        self.label = tf.placeholder(tf.int32, [None])\n",
    "        self.G = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "        initializer = tf.keras.initializers.VarianceScaling(scale=1.0)\n",
    "\n",
    "        dense1 = tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "        dense2 = tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "        dense3 = tf.keras.layers.Dense(self.n_actions, activation=None, kernel_initializer=initializer)\n",
    "\n",
    "        l1 = dense1(self.input)\n",
    "        l2 = dense2(l1)\n",
    "        l3 = dense3(l2)\n",
    "\n",
    "        self.actions = tf.nn.softmax(l3)\n",
    "\n",
    "        neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=l3, labels=self.label)\n",
    "        loss = tf.reduce_mean(neg_log_prob * self.G)\n",
    "        self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        probs = self.sess.run(self.actions, feed_dict={self.input: state})[0]\n",
    "        return np.random.choice(range(self.n_actions), p=probs)\n",
    "\n",
    "    def store_transition(self, state, action, reward):\n",
    "        self.state_memory.append(state)\n",
    "        self.action_memory.append(action)\n",
    "        self.reward_memory.append(reward)\n",
    "\n",
    "    def learn(self):\n",
    "        state_mem = np.array(self.state_memory)\n",
    "        action_mem = np.array(self.action_memory)\n",
    "        rewards = np.array(self.reward_memory)\n",
    "\n",
    "        G = np.zeros_like(rewards, dtype=np.float32)\n",
    "        for t in range(len(rewards)):\n",
    "            discount = 1\n",
    "            G_sum = 0\n",
    "            for k in range(t, len(rewards)):\n",
    "                G_sum += rewards[k] * discount\n",
    "                discount *= self.gamma\n",
    "            G[t] = G_sum\n",
    "\n",
    "        G -= np.mean(G)\n",
    "        G /= np.std(G) if np.std(G) > 0 else 1\n",
    "\n",
    "        self.sess.run(self.train_op, feed_dict={\n",
    "            self.input: state_mem,\n",
    "            self.label: action_mem,\n",
    "            self.G: G\n",
    "        })\n",
    "\n",
    "        self.state_memory, self.action_memory, self.reward_memory = [], [], []\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        self.saver.save(self.sess, self.chkpt_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.saver.restore(self.sess, self.chkpt_file)\n",
    "\n",
    "# === TRAINING SCRIPT ===\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    agent = PolicyGradientAgent(lr=0.001, gamma=0.99)\n",
    "    n_episodes = 500\n",
    "    scores = []\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "\n",
    "        while not done:\n",
    "            if ep % 10 == 0:  # 👀 Render every 10 episodes\n",
    "                env.render()\n",
    "\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.store_transition(state, action, reward)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "        agent.learn()\n",
    "        scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores[-50:])\n",
    "        print(f\"Episode {ep + 1}, Score: {score:.2f}, Avg (50): {avg_score:.2f}\")\n",
    "\n",
    "    agent.save_checkpoint()\n",
    "    env.close()\n",
    "\n",
    "    # 📊 Plot results\n",
    "    plt.plot(scores)\n",
    "    plt.title(\"Policy Gradient on LunarLander (with Visualization)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed9130-80ac-4c4f-ac71-692ae1719695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c593216-9a48-4bb0-9a7e-e477ec21ef2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
